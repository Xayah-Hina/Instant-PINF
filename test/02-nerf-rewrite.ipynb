{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-10T11:44:58.143366Z",
     "start_time": "2024-10-10T11:44:58.135358Z"
    }
   },
   "source": [
    "import argparse\n",
    "\n",
    "args = {'config': 'configs/scalar.txt',\n",
    "        'expname': 'scalar_test1',\n",
    "        'basedir': './log',\n",
    "        'datadir': './data/ScalarReal',\n",
    "        'net_model': 'siren',\n",
    "        'netdepth': 8,\n",
    "        'netwidth': 256,\n",
    "        'netdepth_fine': 8,\n",
    "        'netwidth_fine': 256,\n",
    "        'N_rand': 1024,\n",
    "        'lrate': 0.0005,\n",
    "        'lrate_decay': 500,\n",
    "        'chunk': 32768,\n",
    "        'netchunk': 65536,\n",
    "        'no_batching': True,\n",
    "        'no_reload': False,\n",
    "        'ft_path': None,\n",
    "        'fix_seed': 42,\n",
    "        'fading_layers': 50000,\n",
    "        'tempo_delay': 0,\n",
    "        'vel_delay': 10000,\n",
    "        'N_iter': 600000,\n",
    "        'train_warp': True,\n",
    "        'bbox_min': '0.05',\n",
    "        'bbox_max': '0.9',\n",
    "        'vgg_strides': 4,\n",
    "        'ghostW': 0.07,\n",
    "        'vggW': 0.01,\n",
    "        'overlayW': -0.0,\n",
    "        'd2vW': 2.0,\n",
    "        'nseW': 0.001,\n",
    "        'vol_output_only': False,\n",
    "        'vol_output_W': 128,\n",
    "        'render_only': False,\n",
    "        'render_test': False,\n",
    "        'N_samples': 64,\n",
    "        'N_importance': 64,\n",
    "        'perturb': 1.0,\n",
    "        'use_viewdirs': False,\n",
    "        'i_embed': -1,\n",
    "        'multires': 10,\n",
    "        'multires_views': 4,\n",
    "        'raw_noise_std': 0.0,\n",
    "        'render_factor': 0,\n",
    "        'precrop_iters': 1000,\n",
    "        'precrop_frac': 0.5,\n",
    "        'dataset_type': 'pinf_data',\n",
    "        'testskip': 20,\n",
    "        'shape': 'greek',\n",
    "        'white_bkgd': [1., 1., 1.],\n",
    "        'half_res': 'half',\n",
    "        'factor': 8,\n",
    "        'no_ndc': False,\n",
    "        'lindisp': False,\n",
    "        'spherify': False,\n",
    "        'llffhold': 8,\n",
    "        'i_print': 400,\n",
    "        'i_img': 2000,\n",
    "        'i_weights': 25000,\n",
    "        'i_testset': 50000,\n",
    "        'i_video': 50000}\n",
    "\n",
    "args = argparse.Namespace(**args)\n",
    "DEBUG = False"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T11:44:58.166763Z",
     "start_time": "2024-10-10T11:44:58.150872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import imageio.v2 as imageio\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from typing import Tuple, Union\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_device('cuda')\n",
    "torch.set_default_dtype(torch.float32)"
   ],
   "id": "4e00c36b4f251b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### generate pose spherical\n",
    "\n",
    "- pure torch functions\n",
    "- pure device functions"
   ],
   "id": "21d14598f506ecb8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T11:44:58.194207Z",
     "start_time": "2024-10-10T11:44:58.185675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_translation_matrix(in_device: torch.device, in_t: float) -> torch.Tensor:\n",
    "    return torch.tensor([\n",
    "        [1., 0., 0., 0.],\n",
    "        [0., 1., 0., 0.],\n",
    "        [0., 0., 1., in_t],\n",
    "        [0., 0., 0., 1.]\n",
    "    ], dtype=torch.float32, device=in_device)\n",
    "\n",
    "\n",
    "def create_rotation_matrix_phi(in_device: torch.device, in_phi: float) -> torch.Tensor:\n",
    "    phi_tensor = torch.tensor(data=in_phi, dtype=torch.float32, device=in_device)\n",
    "    cos_phi = torch.cos(input=phi_tensor)\n",
    "    sin_phi = torch.sin(input=phi_tensor)\n",
    "    return torch.tensor(data=[\n",
    "        [1, 0, 0, 0],\n",
    "        [0, cos_phi, -sin_phi, 0],\n",
    "        [0, sin_phi, cos_phi, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ], dtype=torch.float32, device=in_device)\n",
    "\n",
    "\n",
    "def create_rotation_matrix_theta(in_device: torch.device, in_theta: float) -> torch.Tensor:\n",
    "    theta_tensor = torch.tensor(data=in_theta, dtype=torch.float32, device=in_device)\n",
    "    cos_theta = torch.cos(input=theta_tensor)\n",
    "    sin_theta = torch.sin(input=theta_tensor)\n",
    "    return torch.tensor(data=[\n",
    "        [cos_theta, 0, -sin_theta, 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [sin_theta, 0, cos_theta, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ], dtype=torch.float32, device=in_device)\n",
    "\n",
    "\n",
    "def generate_pose_spherical(in_device: torch.device, in_theta: float, in_phi: float, in_radius: float,\n",
    "                            in_rotZ: bool, in_wx: float, in_wy: float, in_wz: float) -> torch.Tensor:\n",
    "    theta_rad = in_theta * torch.pi / 180.0\n",
    "    phi_rad = in_phi * torch.pi / 180.0\n",
    "\n",
    "    c2w = create_translation_matrix(in_device=in_device, in_t=in_radius)\n",
    "    c2w = create_rotation_matrix_phi(in_device=in_device, in_phi=phi_rad) @ c2w\n",
    "    c2w = create_rotation_matrix_theta(in_device=in_device, in_theta=theta_rad) @ c2w\n",
    "\n",
    "    if in_rotZ:\n",
    "        # Swap yz to keep right-hand coordinate system\n",
    "        swap_yz_matrix = torch.tensor(data=[\n",
    "            [-1, 0, 0, 0],\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 1, 0, 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ], dtype=torch.float32, device=in_device)\n",
    "        c2w = swap_yz_matrix @ c2w\n",
    "\n",
    "    translation = torch.tensor([\n",
    "        [1, 0, 0, in_wx],\n",
    "        [0, 1, 0, in_wy],\n",
    "        [0, 0, 1, in_wz],\n",
    "        [0, 0, 0, 1]\n",
    "    ], dtype=torch.float32, device=in_device)\n",
    "    c2w = translation @ c2w\n",
    "\n",
    "    return c2w"
   ],
   "id": "d8e234175c737d5d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### load pinf frame data\n",
    "\n",
    "- pure numpy functions"
   ],
   "id": "4e291bb182d03311"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-10-10T11:44:58.211588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def resample_images(in_images: np.ndarray, in_factor: float) -> np.ndarray:\n",
    "    ret_images = np.zeros((in_images.shape[0], math.floor(in_images.shape[1] * in_factor),\n",
    "                           math.floor(in_images.shape[2] * in_factor), in_images.shape[3]))\n",
    "    for _ in range(in_images.shape[0]):\n",
    "        ret_images[_] = cv2.resize(in_images[_], (ret_images.shape[2], ret_images.shape[1]),\n",
    "                                   interpolation=cv2.INTER_AREA)\n",
    "    return ret_images\n",
    "\n",
    "\n",
    "def load_pinf_frame_data(in_type: str, in_skip: int, in_resample: float) -> Tuple[\n",
    "    np.ndarray, np.ndarray, np.ndarray, dict]:\n",
    "    all_images = []\n",
    "    all_poses = []\n",
    "    all_time_steps = []\n",
    "    ret_params = {}\n",
    "    with open(os.path.normpath(os.path.join(args.datadir, 'info.json')), 'r') as fp:\n",
    "        _meta = json.load(fp)\n",
    "        if (in_type + '_videos') not in _meta:\n",
    "            raise ValueError(f'No {in_type} videos found in the dataset')\n",
    "\n",
    "        ret_params['camera_angle_x'] = []\n",
    "        for _video in _meta[in_type + '_videos']:\n",
    "            # load images, poses and time steps\n",
    "            _image_array = []\n",
    "            _pose_array = []\n",
    "            _time_step_array = []\n",
    "            _reader = imageio.get_reader(os.path.normpath(os.path.join(args.datadir, _video['file_name'])))\n",
    "            for _idx in range(0, _video['frame_num'], in_skip):\n",
    "                _reader.set_image_index(_idx)\n",
    "                _image_array.append(_reader.get_next_data())\n",
    "                _pose_array.append(_video['transform_matrix'])\n",
    "                _time_step_array.append(_idx * 1. / _video['frame_num'])\n",
    "            _reader.close()\n",
    "            all_images.append((np.array(_image_array) / 255.).astype(np.float32))\n",
    "            all_poses.append(np.array(_pose_array).astype(np.float32))\n",
    "            all_time_steps.append(np.array(_time_step_array).astype(np.float32))\n",
    "            ret_params['camera_angle_x'].append(float(_video['camera_angle_x']))\n",
    "\n",
    "        ret_params['near'] = float(_meta['near'])\n",
    "        ret_params['far'] = float(_meta['far'])\n",
    "        ret_params['phi'] = float(_meta['phi'])\n",
    "        ret_params['rotZ'] = (_meta['rot'] == 'Z')\n",
    "        ret_params['r_center'] = np.array(_meta['render_center']).astype(np.float32)\n",
    "        ret_params['bkg_color'] = np.array(_meta['frame_bkg_color']).astype(np.float32)\n",
    "\n",
    "    ret_images_np = np.concatenate(all_images, 0)\n",
    "    ret_poses_np = np.concatenate(all_poses, 0)\n",
    "    ret_time_steps_np = np.concatenate(all_time_steps, 0)\n",
    "\n",
    "    ret_images_resampled_np = resample_images(in_images=ret_images_np, in_factor=in_resample)\n",
    "    return ret_images_resampled_np, ret_poses_np, ret_time_steps_np, ret_params\n",
    "\n",
    "\n",
    "TRAIN_IMAGES, TRAIN_POSES, TRAIN_TIME_STEPS, TRAIN_PARAMS = load_pinf_frame_data(in_type='train', in_skip=1,\n",
    "                                                                                 in_resample=0.5 if args.half_res == 'half' else 1.0)\n",
    "VAR_IMAGES, VAR_POSES, VAR_TIME_STEPS, VAR_PARAMS = load_pinf_frame_data(in_type='train', in_skip=args.testskip,\n",
    "                                                                         in_resample=0.5 if args.half_res == 'half' else 1.0)\n",
    "TEST_IMAGES, TEST_POSES, TEST_TIME_STEPS, TEST_PARAMS = load_pinf_frame_data(in_type='train', in_skip=args.testskip,\n",
    "                                                                             in_resample=0.5 if args.half_res == 'half' else 1.0)"
   ],
   "id": "dec1410748c8238d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T11:44:34.120425Z",
     "start_time": "2024-10-10T11:44:34.110938Z"
    }
   },
   "cell_type": "code",
   "source": "print(TRAIN_PARAMS)",
   "id": "49cc4a7a317d9aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'camera_angle_x': 0.40746459248665245, 'near': 1.1, 'far': 1.5, 'phi': 20.0, 'rotZ': False, 'r_center': array([ 0.338207  ,  0.38795385, -0.26092097], dtype=float32), 'bkg_color': array([0., 0., 0.], dtype=float32)}\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
