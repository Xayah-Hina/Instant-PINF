{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-14T15:31:11.311932Z",
     "start_time": "2024-10-14T15:31:11.299172Z"
    }
   },
   "source": [
    "import argparse\n",
    "\n",
    "args = {'config': 'configs/scalar.txt',\n",
    "        'expname': 'scalar_test1',\n",
    "        'basedir': './log',\n",
    "        'datadir': './data/ScalarReal',\n",
    "        'net_model': 'siren',\n",
    "        'netdepth': 8,\n",
    "        'netwidth': 256,\n",
    "        'netdepth_fine': 8,\n",
    "        'netwidth_fine': 256,\n",
    "        'N_rand': 1024,\n",
    "        'lrate': 0.0005,\n",
    "        'lrate_decay': 500,\n",
    "        'chunk': 32768,\n",
    "        'netchunk': 65536,\n",
    "        'no_batching': True,\n",
    "        'no_reload': False,\n",
    "        'ft_path': None,\n",
    "        'fix_seed': 42,\n",
    "        'fading_layers': 50000,\n",
    "        'tempo_delay': 0,\n",
    "        'vel_delay': 10000,\n",
    "        'N_iter': 600000,\n",
    "        'train_warp': True,\n",
    "        'bbox_min': '0.05',\n",
    "        'bbox_max': '0.9',\n",
    "        'vgg_strides': 4,\n",
    "        'ghostW': 0.07,\n",
    "        'vggW': 0.01,\n",
    "        'overlayW': -0.0,\n",
    "        'd2vW': 2.0,\n",
    "        'nseW': 0.001,\n",
    "        'vol_output_only': False,\n",
    "        'vol_output_W': 128,\n",
    "        'render_only': False,\n",
    "        'render_test': False,\n",
    "        'N_samples': 64,\n",
    "        'N_importance': 64,\n",
    "        'perturb': 1.0,\n",
    "        'use_viewdirs': False,\n",
    "        'i_embed': -1,\n",
    "        'multires': 10,\n",
    "        'multires_views': 4,\n",
    "        'raw_noise_std': 0.0,\n",
    "        'render_factor': 0,\n",
    "        'precrop_iters': 1000,\n",
    "        'precrop_frac': 0.5,\n",
    "        'dataset_type': 'pinf_data',\n",
    "        'testskip': 20,\n",
    "        'shape': 'greek',\n",
    "        'white_bkgd': [1., 1., 1.],\n",
    "        'half_res': 'half',\n",
    "        'factor': 8,\n",
    "        'no_ndc': False,\n",
    "        'lindisp': False,\n",
    "        'spherify': False,\n",
    "        'llffhold': 8,\n",
    "        'i_print': 400,\n",
    "        'i_img': 2000,\n",
    "        'i_weights': 25000,\n",
    "        'i_testset': 50000,\n",
    "        'i_video': 50000}\n",
    "\n",
    "args = argparse.Namespace(**args)\n",
    "DEBUG = False"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T15:31:16.906468Z",
     "start_time": "2024-10-14T15:31:11.360134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import imageio.v2 as imageio\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from typing import Tuple, Union\n",
    "\n",
    "host = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_device('cuda')\n",
    "torch.set_default_dtype(torch.float32)"
   ],
   "id": "4e00c36b4f251b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### generate pose spherical\n",
    "\n",
    "- pure torch functions\n",
    "- pure device functions"
   ],
   "id": "21d14598f506ecb8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T15:31:17.095483Z",
     "start_time": "2024-10-14T15:31:17.086798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_translation_matrix(in_device: torch.device, in_t: float) -> torch.Tensor:\n",
    "    return torch.tensor([\n",
    "        [1., 0., 0., 0.],\n",
    "        [0., 1., 0., 0.],\n",
    "        [0., 0., 1., in_t],\n",
    "        [0., 0., 0., 1.]\n",
    "    ], dtype=torch.float32, device=in_device)\n",
    "\n",
    "\n",
    "def create_rotation_matrix_phi(in_device: torch.device, in_phi: float) -> torch.Tensor:\n",
    "    _phi_tensor = torch.tensor(data=in_phi, dtype=torch.float32, device=in_device)\n",
    "    _cos_phi = torch.cos(input=_phi_tensor)\n",
    "    _sin_phi = torch.sin(input=_phi_tensor)\n",
    "    return torch.tensor(data=[\n",
    "        [1, 0, 0, 0],\n",
    "        [0, _cos_phi, -_sin_phi, 0],\n",
    "        [0, _sin_phi, _cos_phi, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ], dtype=torch.float32, device=in_device)\n",
    "\n",
    "\n",
    "def create_rotation_matrix_theta(in_device: torch.device, in_theta: float) -> torch.Tensor:\n",
    "    _theta_tensor = torch.tensor(data=in_theta, dtype=torch.float32, device=in_device)\n",
    "    _cos_theta = torch.cos(input=_theta_tensor)\n",
    "    _sin_theta = torch.sin(input=_theta_tensor)\n",
    "    return torch.tensor(data=[\n",
    "        [_cos_theta, 0, -_sin_theta, 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [_sin_theta, 0, _cos_theta, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ], dtype=torch.float32, device=in_device)\n",
    "\n",
    "\n",
    "def generate_pose_spherical(in_device: torch.device, in_theta: float, in_phi: float, in_radius: float,\n",
    "                            in_rotZ: bool, in_wx: float, in_wy: float, in_wz: float) -> torch.Tensor:\n",
    "    _theta_rad = in_theta * torch.pi / 180.0\n",
    "    _phi_rad = in_phi * torch.pi / 180.0\n",
    "\n",
    "    ret_c2w = create_translation_matrix(in_device=in_device, in_t=in_radius)\n",
    "    ret_c2w = create_rotation_matrix_phi(in_device=in_device, in_phi=_phi_rad) @ ret_c2w\n",
    "    ret_c2w = create_rotation_matrix_theta(in_device=in_device, in_theta=_theta_rad) @ ret_c2w\n",
    "\n",
    "    if in_rotZ:\n",
    "        # Swap yz to keep right-hand coordinate system\n",
    "        _swap_yz_matrix = torch.tensor(data=[\n",
    "            [-1, 0, 0, 0],\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 1, 0, 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ], dtype=torch.float32, device=in_device)\n",
    "        ret_c2w = _swap_yz_matrix @ ret_c2w\n",
    "\n",
    "    _translation = torch.tensor([\n",
    "        [1, 0, 0, in_wx],\n",
    "        [0, 1, 0, in_wy],\n",
    "        [0, 0, 1, in_wz],\n",
    "        [0, 0, 0, 1]\n",
    "    ], dtype=torch.float32, device=in_device)\n",
    "    ret_c2w = _translation @ ret_c2w\n",
    "\n",
    "    return ret_c2w\n",
    "\n",
    "\n",
    "def generate_position_encoding_fn(in_multires: int):\n",
    "    _input_dims = 3\n",
    "    _max_freq_log2 = in_multires - 1\n",
    "    _num_freq = in_multires\n",
    "    _freq_bands = 2. ** torch.linspace(start=0., end=_max_freq_log2, steps=_num_freq)\n",
    "\n",
    "    _embed_fns = [lambda x: x]\n",
    "    ret_out_dim = _input_dims\n",
    "    for _freq in _freq_bands:\n",
    "        for _p_fn in [torch.sin, torch.cos]:\n",
    "            _embed_fns.append(lambda x, p_fn=_p_fn, freq=_freq: p_fn(x * freq))\n",
    "            ret_out_dim += _input_dims\n",
    "\n",
    "    ret_embed_fn = lambda x: torch.cat([fn(x) for fn in _embed_fns], -1)\n",
    "    return ret_embed_fn, ret_out_dim"
   ],
   "id": "d8e234175c737d5d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### load pinf frame data\n",
    "\n",
    "- pure numpy functions"
   ],
   "id": "4e291bb182d03311"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T15:31:22.722217Z",
     "start_time": "2024-10-14T15:31:17.103587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def resample_images(in_images: np.ndarray, in_factor: float) -> np.ndarray:\n",
    "    ret_images = np.zeros((in_images.shape[0], math.floor(in_images.shape[1] * in_factor),\n",
    "                           math.floor(in_images.shape[2] * in_factor), in_images.shape[3]), dtype=np.float32)\n",
    "    for _ in range(in_images.shape[0]):\n",
    "        ret_images[_] = cv2.resize(in_images[_], (ret_images.shape[2], ret_images.shape[1]),\n",
    "                                   interpolation=cv2.INTER_AREA)\n",
    "    return ret_images\n",
    "\n",
    "\n",
    "def load_pinf_frame_data(in_type: str, in_skip: int, in_resample: float) -> Tuple[\n",
    "    np.ndarray, np.ndarray, np.ndarray, dict]:\n",
    "    _all_images = []\n",
    "    _all_poses = []\n",
    "    _all_time_steps = []\n",
    "    ret_params = {}\n",
    "    with open(os.path.normpath(os.path.join(args.datadir, 'info.json')), 'r') as fp:\n",
    "        _meta = json.load(fp)\n",
    "        if (in_type + '_videos') not in _meta:\n",
    "            raise ValueError(f'No {in_type} videos found in the dataset')\n",
    "\n",
    "        ret_params['camera_angle_x'] = []\n",
    "        for _video in _meta[in_type + '_videos']:\n",
    "            # load images, poses and time steps\n",
    "            _image_array = []\n",
    "            _pose_array = []\n",
    "            _time_step_array = []\n",
    "            _reader = imageio.get_reader(os.path.normpath(os.path.join(args.datadir, _video['file_name'])))\n",
    "            for _idx in range(0, _video['frame_num'], in_skip):\n",
    "                _reader.set_image_index(_idx)\n",
    "                _image_array.append(_reader.get_next_data())\n",
    "                _pose_array.append(_video['transform_matrix'])\n",
    "                _time_step_array.append(_idx * 1. / _video['frame_num'])\n",
    "            _reader.close()\n",
    "            _all_images.append((np.array(_image_array, dtype=np.float32) / 255.))\n",
    "            _all_poses.append(np.array(_pose_array, dtype=np.float32))\n",
    "            _all_time_steps.append(np.array(_time_step_array, dtype=np.float32))\n",
    "            ret_params['camera_angle_x'].append(float(_video['camera_angle_x']))\n",
    "\n",
    "        ret_params['near'] = float(_meta['near'])\n",
    "        ret_params['far'] = float(_meta['far'])\n",
    "        ret_params['phi'] = float(_meta['phi'])\n",
    "        ret_params['rotZ'] = (_meta['rot'] == 'Z')\n",
    "        ret_params['r_center'] = np.array(_meta['render_center'], dtype=np.float32)\n",
    "        ret_params['bkg_color'] = np.array(_meta['frame_bkg_color'], dtype=np.float32)\n",
    "        ret_params['voxel_matrix'] = np.array(_meta['voxel_matrix'], dtype=np.float32)\n",
    "        ret_params['voxel_scale'] = np.broadcast_to(_meta['voxel_scale'], [3]).astype(np.float32)\n",
    "\n",
    "    ret_images_np = np.concatenate(_all_images, 0)\n",
    "    ret_poses_np = np.concatenate(_all_poses, 0)\n",
    "    ret_time_steps_np = np.concatenate(_all_time_steps, 0)\n",
    "\n",
    "    ret_images_resampled_np = resample_images(in_images=ret_images_np, in_factor=in_resample)\n",
    "    return ret_images_resampled_np, ret_poses_np, ret_time_steps_np, ret_params\n",
    "\n",
    "\n",
    "TRAIN_IMAGES, TRAIN_POSES, TRAIN_TIME_STEPS, TRAIN_PARAMS = load_pinf_frame_data(in_type='train', in_skip=20,\n",
    "                                                                                 in_resample=0.5 if args.half_res == 'half' else 1.0)\n",
    "# VAR_IMAGES, VAR_POSES, VAR_TIME_STEPS, VAR_PARAMS = load_pinf_frame_data(in_type='train', in_skip=args.testskip,\n",
    "#                                                                          in_resample=0.5 if args.half_res == 'half' else 1.0)\n",
    "# TEST_IMAGES, TEST_POSES, TEST_TIME_STEPS, TEST_PARAMS = load_pinf_frame_data(in_type='train', in_skip=args.testskip,\n",
    "#                                                                              in_resample=0.5 if args.half_res == 'half' else 1.0)"
   ],
   "id": "dec1410748c8238d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T15:31:22.798163Z",
     "start_time": "2024-10-14T15:31:22.740676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "VOXEL_TRAN = torch.tensor(data=np.stack(\n",
    "    [TRAIN_PARAMS['voxel_matrix'][:, 2], TRAIN_PARAMS['voxel_matrix'][:, 1], TRAIN_PARAMS['voxel_matrix'][:, 0],\n",
    "     TRAIN_PARAMS['voxel_matrix'][:, 3]], axis=1), device=host)\n",
    "VOXEL_TRAN_INV = torch.linalg.inv(VOXEL_TRAN)\n",
    "VOXEL_SCALE = torch.tensor(TRAIN_PARAMS['voxel_scale'], device=host)"
   ],
   "id": "49cc4a7a317d9aa",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T15:31:23.017236Z",
     "start_time": "2024-10-14T15:31:22.847850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pos_world2smoke(points_world: torch.Tensor, w2s: torch.Tensor, scale: torch.Tensor) -> torch.Tensor:\n",
    "    pos_rot = torch.sum(points_world[..., None, :] * (w2s[:3, :3]), -1)  # 4.world to 3.target \n",
    "    pos_off = (w2s[:3, -1]).expand(pos_rot.shape)  # 4.world to 3.target \n",
    "    new_pose = pos_rot + pos_off\n",
    "    pos_scale = new_pose / (scale)  # 3.target to 2.simulation\n",
    "    return pos_scale\n",
    "\n",
    "\n",
    "class BBoxTool:\n",
    "    def __init__(self, in_smoke_tran_inv: torch.Tensor, in_smoke_scale: torch.Tensor, in_min: float, in_max: float):\n",
    "        self.s_w2s = in_smoke_tran_inv.clone().detach().expand([4, 4])\n",
    "        self.s_scale = in_smoke_scale.clone().detach().expand([3])\n",
    "        self.s_min = torch.tensor(in_min).expand([3])\n",
    "        self.s_max = torch.tensor(in_max).expand([3])\n",
    "\n",
    "    def is_inside(self, inputs_points: torch.Tensor) -> torch.Tensor:\n",
    "        # points_smoke = pos_world2smoke(points_world=inputs_points, w2s=self.s_w2s, scale=self.s_scale)\n",
    "        pass\n",
    "\n",
    "\n",
    "BBOX_MODEL = BBoxTool(in_smoke_tran_inv=VOXEL_TRAN_INV, in_smoke_scale=VOXEL_SCALE, in_min=float(args.bbox_min),\n",
    "                      in_max=float(args.bbox_max))"
   ],
   "id": "3696c7532033bcf9",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T15:31:23.036418Z",
     "start_time": "2024-10-14T15:31:23.030705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SineLayer(torch.nn.Module):\n",
    "    def __init__(self, in_features_in: torch.Tensor, in_features_out: torch.Tensor, in_bias: bool, in_is_first: bool,\n",
    "                 in_omega_0: float):\n",
    "        super(SineLayer, self).__init__()\n",
    "        self.omega_0 = in_omega_0\n",
    "        self.linear = torch.nn.Linear(in_features_in, in_features_out, bias=in_bias)\n",
    "        with torch.no_grad():\n",
    "            if in_is_first:\n",
    "                self.linear.weight.uniform_(-1. / in_features_in, 1. / in_features_in)\n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / in_features_in) / in_omega_0,\n",
    "                                            np.sqrt(6 / in_features_in) / in_omega_0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return torch.sin(self.omega_0 * self.linear(x))\n",
    "\n",
    "    def forward_with_intermediate(self, x: torch.Tensor):\n",
    "        intermediate = self.omega_0 * self.linear(x)\n",
    "        return torch.sin(intermediate), intermediate\n",
    "\n",
    "\n",
    "class SIREN_VEL(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SIREN_VEL, self).__init__()\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        pass\n",
    "\n",
    "\n",
    "class SIREN_NeRFt(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SIREN_NeRFt, self).__init__()\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        pass"
   ],
   "id": "bf7363d3a0116b1f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T15:31:23.057014Z",
     "start_time": "2024-10-14T15:31:23.053781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_nerf():\n",
    "    pass"
   ],
   "id": "824ae94bff0a9a48",
   "outputs": [],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
