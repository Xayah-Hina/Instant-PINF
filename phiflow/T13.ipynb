{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 为什么会报错？\n",
    "```\n",
    "RuntimeError: Output 0 of UnbindBackward0 is a view and its base or another view of its base has been modified inplace. This view is the output of a function that returns multiple views. Such functions do not allow the output views to be modified inplace. You should replace the inplace operation by an out-of-place one.\n",
    "```"
   ],
   "id": "fc3a2936e4c69a08"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-18T07:33:54.978250Z",
     "start_time": "2025-01-18T07:33:52.797430Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import phi.torch.flow as ptf\n",
    "\n",
    "import tqdm\n",
    "\n",
    "device = torch.device('cuda')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T07:33:54.985349Z",
     "start_time": "2025-01-18T07:33:54.981259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BOUNDS = ptf.Box(x=1, y=1, z=1)\n",
    "RESOLUTION = 100"
   ],
   "id": "79a5cdfddcb88a02",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T07:33:55.536622Z",
     "start_time": "2025-01-18T07:33:55.172379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "index1 = 0\n",
    "index2 = index1 + 5\n",
    "den1_np = np.load(f'origin/origin_{index1:03d}.npz')['density']\n",
    "den2_np = np.load(f'origin/origin_{index2:03d}.npz')['density']\n",
    "den1_gpu = torch.tensor(den1_np, dtype=torch.float32, device=device)\n",
    "den2_gpu = torch.tensor(den2_np, dtype=torch.float32, device=device)\n",
    "\n",
    "DENSITY1 = ptf.CenteredGrid(\n",
    "    values=ptf.wrap(den1_gpu, ptf.spatial('x,y,z')),\n",
    "    extrapolation=ptf.extrapolation.ZERO_GRADIENT,\n",
    "    bounds=BOUNDS,\n",
    "    resolution=ptf.spatial(x=RESOLUTION, y=RESOLUTION, z=RESOLUTION),\n",
    ")\n",
    "DENSITY2 = ptf.CenteredGrid(\n",
    "    values=ptf.wrap(den2_gpu, ptf.spatial('x,y,z')),\n",
    "    extrapolation=ptf.extrapolation.ZERO_GRADIENT,\n",
    "    bounds=BOUNDS,\n",
    "    resolution=ptf.spatial(x=RESOLUTION, y=RESOLUTION, z=RESOLUTION),\n",
    ")\n",
    "VELOCITY0 = ptf.StaggeredGrid(\n",
    "    values=0,\n",
    "    extrapolation=ptf.extrapolation.ZERO,\n",
    "    bounds=BOUNDS,\n",
    "    resolution=ptf.spatial(x=RESOLUTION, y=RESOLUTION, z=RESOLUTION),\n",
    ")\n",
    "INFLOW = ptf.CenteredGrid(\n",
    "    values=ptf.Sphere(center=ptf.tensor([0.5, 0, 0.5], ptf.channel(vector='x,y,z')), radius=0.05),\n",
    "    extrapolation=ptf.extrapolation.ZERO,\n",
    "    bounds=BOUNDS,\n",
    "    resolution=ptf.spatial(x=RESOLUTION, y=RESOLUTION, z=RESOLUTION),\n",
    ")\n",
    "\n",
    "\n",
    "# @ptf.jit_compile\n",
    "def step(v, s, p, dt, inflow_rate, inflow, FORCE):\n",
    "    s = ptf.advect.mac_cormack(s, v, dt) + inflow_rate * ptf.resample(inflow, to=s, soft=True)\n",
    "    buoyancy = ptf.resample(s * (0, 0.1, 0), to=v) + ptf.resample(FORCE, to=v)\n",
    "    v = ptf.advect.semi_lagrangian(v, v, dt) + buoyancy * dt\n",
    "    v, p = ptf.fluid.make_incompressible(v, (), ptf.Solve('auto', 1e-3, x0=p))\n",
    "    return v, s, p\n",
    "\n",
    "\n",
    "DENSITY = DENSITY1\n",
    "VELOCITY = VELOCITY0"
   ],
   "id": "e44571c42bd9e49d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T07:33:58.678655Z",
     "start_time": "2025-01-18T07:33:55.762662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.linspace(0.2, 0.8, 3, dtype=torch.float32, device=device)\n",
    "y = torch.linspace(0.2, 0.8, 3, dtype=torch.float32, device=device)\n",
    "z = torch.linspace(0.2, 0.8, 3, dtype=torch.float32, device=device)\n",
    "grid_x, grid_y, grid_z = torch.meshgrid(x, y, z, indexing='ij')\n",
    "\n",
    "LOCATIONS = torch.stack([grid_x, grid_y, grid_z], dim=-1).reshape(-1, 3)  # [27, 3]\n",
    "DIRECTIONS = torch.randn_like(LOCATIONS, dtype=torch.float32, device=device, requires_grad=True)  # [27, 3]\n",
    "\n",
    "\n",
    "# OPTIMIZER = torch.optim.RAdam([DIRECTIONS], lr=0.001)\n",
    "\n",
    "\n",
    "def my_func(xx):\n",
    "    ret = A * ptf.math.exp(-ptf.length(xx - loca) ** 2 / (2 * sigma ** 2))\n",
    "    return ptf.vec(x=ret, y=ret, z=ret)\n",
    "\n",
    "\n",
    "A = 0.2  # 高斯幅值\n",
    "sigma = 0.2  # 标准差，控制衰减范围\n",
    "LAMBDA_FIELDS = []\n",
    "for loca in LOCATIONS:\n",
    "    LAMBDA = ptf.CenteredGrid(\n",
    "        values=my_func,\n",
    "        extrapolation=ptf.extrapolation.ZERO_GRADIENT,\n",
    "        bounds=BOUNDS,\n",
    "        resolution=ptf.spatial(x=RESOLUTION, y=RESOLUTION, z=RESOLUTION),\n",
    "    )\n",
    "    LAMBDA_FIELDS.append(LAMBDA)\n",
    "\n",
    "DIRECTION_FIELDS = []\n",
    "for dire in DIRECTIONS:\n",
    "    DIRECTION = ptf.CenteredGrid(\n",
    "        values=ptf.wrap(dire, ptf.channel(vector='x,y,z')),\n",
    "        extrapolation=ptf.extrapolation.ZERO_GRADIENT,\n",
    "        bounds=BOUNDS,\n",
    "        resolution=ptf.spatial(x=RESOLUTION, y=RESOLUTION, z=RESOLUTION),\n",
    "    )\n",
    "    DIRECTION_FIELDS.append(DIRECTION)\n",
    "\n",
    "all_iterations = 100\n",
    "losses = []\n",
    "for _ in tqdm.trange(all_iterations):\n",
    "    # OPTIMIZER.zero_grad()\n",
    "\n",
    "    first = True\n",
    "    for _1, _2 in zip(LAMBDA_FIELDS, DIRECTION_FIELDS):\n",
    "        if first:\n",
    "            FORCE_FIELD = _1 * _2\n",
    "            first = False\n",
    "        else:\n",
    "            FORCE_FIELD = FORCE_FIELD + _1 * _2\n",
    "\n",
    "\n",
    "    VELOCITY = ptf.resample(FORCE_FIELD, to=VELOCITY) * 0.2\n",
    "    DENSITY3 = ptf.advect.mac_cormack(DENSITY, VELOCITY, 0.2) + 0.2 * ptf.resample(INFLOW, to=DENSITY, soft=True)\n",
    "\n",
    "    loss = torch.nn.functional.mse_loss(DENSITY2.values.native('x,y,z'), DENSITY3.values.native('x,y,z'))\n",
    "    loss.backward()\n",
    "    # OPTIMIZER.step()\n",
    "\n",
    "    print(f'loss: {loss.item()}')\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    DENSITY = DENSITY3"
   ],
   "id": "c5a5ec304abe7525",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:00<01:37,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0001653059880482033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:01<03:15,  1.97s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 58\u001B[0m\n\u001B[0;32m     55\u001B[0m DENSITY3 \u001B[38;5;241m=\u001B[39m ptf\u001B[38;5;241m.\u001B[39madvect\u001B[38;5;241m.\u001B[39mmac_cormack(DENSITY, VELOCITY, \u001B[38;5;241m0.2\u001B[39m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m0.2\u001B[39m \u001B[38;5;241m*\u001B[39m ptf\u001B[38;5;241m.\u001B[39mresample(INFLOW, to\u001B[38;5;241m=\u001B[39mDENSITY, soft\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     57\u001B[0m loss \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39mmse_loss(DENSITY2\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mnative(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx,y,z\u001B[39m\u001B[38;5;124m'\u001B[39m), DENSITY3\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mnative(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx,y,z\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m---> 58\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     59\u001B[0m \u001B[38;5;66;03m# OPTIMIZER.step()\u001B[39;00m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;241m.\u001B[39mitem()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_tensor.py:581\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    572\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    573\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    574\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    579\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    580\u001B[0m     )\n\u001B[1;32m--> 581\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    582\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    583\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\graph.py:825\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    823\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    824\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 825\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    827\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    828\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    829\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
