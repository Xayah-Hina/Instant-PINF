{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup Datasets\n",
    "1. image_batch['image']\n",
    "2. image_batch['image_idx']"
   ],
   "id": "dd6133957f2dbe6f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-21T12:55:45.060971Z"
    }
   },
   "source": [
    "import src.dataloader\n",
    "import torch\n",
    "import pathlib\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "dataloader = src.dataloader.load_train_data(\n",
    "    dataset_dir=pathlib.Path(\"C:/Users/imeho/Documents/DataSets/InstantPINF/ScalarReal\"),\n",
    "    split=\"train\",\n",
    "    device=torch.device(\"cuda\"),\n",
    "    frame_skip=1,\n",
    "    exclude_batch_keys_from_device=[\"image\", \"image_idx\"],\n",
    ")\n",
    "image_batch = next(iter(dataloader))\n",
    "sorted_indices = torch.argsort(image_batch[\"image_idx\"])\n",
    "image_batch[\"image_idx\"] = image_batch[\"image_idx\"].index_select(0, sorted_indices).to(device)\n",
    "image_batch[\"image\"] = image_batch[\"image\"].index_select(0, sorted_indices).to(device)\n",
    "\n",
    "print(f'image shape: {image_batch[\"image\"].shape}')\n",
    "print(f'image indices shape: {image_batch[\"image_idx\"].shape}')\n",
    "print(f'image device: {image_batch[\"image\"].device}')\n",
    "print(f'image indices: {image_batch[\"image_idx\"].device}')\n",
    "memory_image = image_batch['image'].element_size() * image_batch['image'].numel()\n",
    "memory_indices = image_batch['image_idx'].element_size() * image_batch['image_idx'].numel()\n",
    "print(f'Memory of image: {memory_image / 1024 / 1024:.2f} MB')\n",
    "print(f'Memory of indices: {memory_indices / 1024 / 1024:.2f} MB')\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup Hash Encoder\n",
    "1. xyzt_encoder(xyzt)"
   ],
   "id": "fb82653119c25203"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T12:48:31.396460Z",
     "start_time": "2024-11-21T12:48:28.143357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import src.encoder\n",
    "import taichi as ti\n",
    "import numpy as np\n",
    "\n",
    "ti.init(arch=ti.cuda)\n",
    "xyzt_encoder = src.encoder.HashEncoderHyFluid(\n",
    "    min_res=np.array([16, 16, 16, 16]),\n",
    "    max_res=np.array([256, 256, 256, 128]),\n",
    "    num_scales=16,\n",
    "    max_params=2 ** 19,\n",
    ")\n",
    "xyzt_encoder.to(device)"
   ],
   "id": "9b3ce0d74e08fe53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Taichi] version 1.7.2, llvm 15.0.1, commit 0131dce9, win, python 3.11.0\n",
      "[Taichi] Starting on arch=cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HashEncoderHyFluid()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup Model & Optimizer\n",
    "1. mlp(xyzt_encoded)\n",
    "2. learned_rgb\n",
    "3. optimizer"
   ],
   "id": "3b375e94d2190507"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T12:48:32.806136Z",
     "start_time": "2024-11-21T12:48:32.128646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nerfstudio.field_components.mlp\n",
    "import src.radam\n",
    "\n",
    "mlp = nerfstudio.field_components.mlp.MLP(\n",
    "    in_dim=xyzt_encoder.num_scales * xyzt_encoder.features_per_level,\n",
    "    num_layers=2,\n",
    "    layer_width=64,\n",
    "    out_dim=1,\n",
    "    out_activation=torch.nn.ReLU(),\n",
    ").to(device)\n",
    "learned_rgb = torch.nn.Parameter(torch.tensor([0.0], device=device))\n",
    "\n",
    "grad_vars = list(mlp.parameters()) + [learned_rgb]\n",
    "embedding_params = list(xyzt_encoder.parameters())\n",
    "\n",
    "optimizer = src.radam.RAdam([\n",
    "    {'params': grad_vars, 'weight_decay': 1e-6},\n",
    "    {'params': embedding_params, 'eps': 1e-15}\n",
    "], lr=0.01, betas=(0.9, 0.99))"
   ],
   "id": "b9858af38cf14b12",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup Ray Sampler & Collider",
   "id": "dd326ffdc61683f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T12:48:33.950924Z",
     "start_time": "2024-11-21T12:48:33.895410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nerfstudio.model_components.ray_generators\n",
    "import nerfstudio.model_components.ray_samplers\n",
    "import nerfstudio.data.pixel_samplers\n",
    "import nerfstudio.model_components.scene_colliders\n",
    "\n",
    "pixel_sampler = nerfstudio.data.pixel_samplers.PixelSamplerConfig(num_rays_per_batch=4096).setup()\n",
    "ray_generator = nerfstudio.model_components.ray_generators.RayGenerator(dataloader.dataset.cameras).to(device)\n",
    "uniform_sampler = nerfstudio.model_components.ray_samplers.UniformSampler(num_samples=192).to(device)\n",
    "near_far_collider = nerfstudio.model_components.scene_colliders.NearFarCollider(near_plane=1.1, far_plane=1.5).to(\n",
    "    device)"
   ],
   "id": "48aa0d5f36df12ed",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Optimization Loop",
   "id": "3c9b0ffc7f7b9d02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T12:55:22.810014Z",
     "start_time": "2024-11-21T12:55:17.578670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from collections import defaultdict\n",
    "import nerfstudio.model_components.losses\n",
    "\n",
    "raw2alpha = lambda raw, dists, act_fn=torch.nn.functional.relu: 1. - torch.exp(-act_fn(raw) * dists)\n",
    "rgb_loss = nerfstudio.model_components.losses.MSELoss()\n",
    "boundary_frames = torch.tensor([119, 239, 359, 479], dtype=torch.int32, device=\"cuda\")\n",
    "\n",
    "\n",
    "def perturb_frames_sample(image_batch, all_frames, batch):\n",
    "    sample_image = batch['image']\n",
    "    sample_idx = batch['indices'].float()\n",
    "\n",
    "    video_starts = [0] + list(torch.cumsum(torch.tensor(all_frames[:-1]), dim=0).numpy())\n",
    "    video_ends = [start + frames - 1 for start, frames in zip(video_starts, all_frames)]\n",
    "\n",
    "    images = image_batch['image']\n",
    "    image_idx = image_batch['image_idx']\n",
    "    num_samples = sample_image.shape[0]\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        current_frame_idx = int(sample_idx[i, 0].item())\n",
    "\n",
    "        # 检查是否为视频的第一个或最后一个帧\n",
    "        is_first_or_last_frame = any(\n",
    "            current_frame_idx == video_starts[j] or current_frame_idx == video_ends[j]\n",
    "            for j in range(len(all_frames))\n",
    "        )\n",
    "        if is_first_or_last_frame:\n",
    "            continue\n",
    "\n",
    "        current_height_idx = int(sample_idx[i, 1].item())\n",
    "        current_width_idx = int(sample_idx[i, 2].item())\n",
    "        perturb_value = (torch.rand(1).item() - 0.5)\n",
    "\n",
    "        if perturb_value > 0:\n",
    "            # 获取下一帧的索引\n",
    "            next_frame_idx = torch.where(image_idx == (current_frame_idx + 1))[0].item()\n",
    "            assert image_idx[next_frame_idx] == (current_frame_idx + 1)\n",
    "            weight_curr = (0.5 - perturb_value) / 0.5\n",
    "            weight_next = perturb_value / 0.5\n",
    "            sample_image[i] = weight_curr * sample_image[i] + weight_next * images[\n",
    "                next_frame_idx, current_height_idx, current_width_idx]\n",
    "            sample_idx[i, 0] = current_frame_idx + perturb_value\n",
    "\n",
    "        elif perturb_value < 0:\n",
    "            # 获取前一帧的索引\n",
    "            prev_frame_idx = torch.where(image_idx == (current_frame_idx - 1))[0].item()\n",
    "            assert image_idx[prev_frame_idx] == (current_frame_idx - 1)\n",
    "            weight_curr = (0.5 + perturb_value) / 0.5\n",
    "            weight_prev = -perturb_value / 0.5\n",
    "            sample_image[i] = weight_curr * sample_image[i] + weight_prev * images[\n",
    "                prev_frame_idx, current_height_idx, current_width_idx]\n",
    "            sample_idx[i, 0] = current_frame_idx + perturb_value\n",
    "\n",
    "    batch['image'] = sample_image\n",
    "    batch['indices'] = sample_idx\n",
    "\n",
    "\n",
    "def interpolate_frame(in_image_batch, boundary_frames, in_batch):\n",
    "    current_frames = in_batch['indices'][:, 0]\n",
    "    next_frames = current_frames + 1\n",
    "    skip_indices = torch.isin(current_frames, boundary_frames)\n",
    "    y_indices = in_batch['indices'][:, 1]\n",
    "    z_indices = in_batch['indices'][:, 2]\n",
    "\n",
    "    # 获取当前帧和下一帧的像素值\n",
    "    current_pixels = in_image_batch['image'][current_frames, y_indices, z_indices]\n",
    "    next_pixels = in_image_batch['image'][torch.where(skip_indices, current_frames, next_frames), y_indices, z_indices]\n",
    "\n",
    "    # 随机插值系数\n",
    "    random_coeff = torch.rand(current_frames.shape[0], 1, device=device)\n",
    "    random_coeff_expanded = random_coeff.expand(-1, 3)\n",
    "\n",
    "    # 计算插值后的像素值\n",
    "    interpolated_pixels = current_pixels * (1 - random_coeff_expanded) + next_pixels * random_coeff_expanded\n",
    "\n",
    "    # 计算插值后的帧数，skip_indices 的帧保持原值\n",
    "    interpolated_indices = torch.where(skip_indices.unsqueeze(-1),\n",
    "                                       current_frames.unsqueeze(-1).float(),\n",
    "                                       current_frames.unsqueeze(-1).float() + random_coeff)\n",
    "    interpolated_indices = interpolated_indices % 120\n",
    "    return interpolated_pixels, interpolated_indices\n",
    "\n",
    "\n",
    "# 定义一个字典存储每句代码的执行时间\n",
    "execution_times = defaultdict(list)\n",
    "# 用于记录每次循环的 loss 值\n",
    "loss_values = []\n",
    "\n",
    "# 模拟循环任务\n",
    "for i in tqdm.tqdm(range(1)):\n",
    "    # 记录每一步的执行时间\n",
    "    start = time.time()\n",
    "    batch = pixel_sampler.sample(image_batch)\n",
    "    execution_times[\"sample\"].append(time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    ray_bundle = near_far_collider(ray_generator(batch['indices']))\n",
    "    execution_times[\"ray_bundle\"].append(time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    ray_samples_uniform = uniform_sampler(ray_bundle)\n",
    "    execution_times[\"ray_samples_uniform\"].append(time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    positions = ray_samples_uniform.frustums.get_positions()\n",
    "    execution_times[\"get_positions\"].append(time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    interpolated_pixels, interpolated_indices = interpolate_frame(image_batch, boundary_frames, batch)\n",
    "    # perturb_frames_sample(image_batch, dataloader.dataset.metadata['all_frames'], batch)\n",
    "    execution_times[\"perturb_frames_sample\"].append(time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    frames_expanded = interpolated_indices.unsqueeze(1).expand(-1, positions.size(1), -1)  # (4096, 192, 1)\n",
    "    xyzt = torch.cat([positions, frames_expanded], dim=-1)  # (4096, 192, 4)\n",
    "    xyzt_flat = xyzt.reshape(-1, 4)\n",
    "    execution_times[\"xyzt\"].append(time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    xyzt_encoded = xyzt_encoder(xyzt_flat)\n",
    "    execution_times[\"xyzt_encoder\"].append(time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    raw_flat = mlp(xyzt_encoded)\n",
    "    execution_times[\"mlp\"].append(time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    raw = raw_flat.reshape(xyzt.shape[0], xyzt.shape[1], raw_flat.shape[-1])\n",
    "    execution_times[\"raw_reshape\"].append(time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    dists = ray_samples_uniform.deltas\n",
    "    rgb = torch.ones(3, device=device) * (0.6 + torch.tanh(learned_rgb) * 0.4)\n",
    "    alpha = raw2alpha(raw[..., -1], dists[..., -1])\n",
    "    weights = alpha * torch.cumprod(torch.cat([torch.ones((alpha.shape[0], 1), device=device), 1. - alpha + 1e-10], -1),\n",
    "                                    -1)[:, :-1]\n",
    "    rgb_map = torch.sum(weights[..., None] * rgb, -2)\n",
    "    execution_times[\"raw2alpha\"].append(time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    loss = rgb_loss(rgb_map, batch['image'])\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    new_lrate = 5e-4 * (0.1 ** (i / 250))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = new_lrate\n",
    "    execution_times[\"optimizing\"].append(time.time() - start)\n",
    "\n",
    "    # 记录 loss 值\n",
    "    loss_values.append(loss.item())\n",
    "\n",
    "# 计算平均耗时并排序\n",
    "avg_execution_times = {key: sum(times) / len(times) for key, times in execution_times.items()}\n",
    "sorted_avg_times = sorted(avg_execution_times.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# 获取平均耗时 Top 5 的步骤\n",
    "top5_keys = [item[0] for item in sorted_avg_times[:5]]\n",
    "\n",
    "# 绘制折线图\n",
    "plt.figure(figsize=(12, 8))\n",
    "for key in top5_keys:\n",
    "    plt.plot(range(1, len(execution_times[key]) + 1), execution_times[key], label=key, marker='o')\n",
    "\n",
    "# 设置图表标题和轴标签\n",
    "plt.title(\"Top 5 Execution Times per Step\", fontsize=14)\n",
    "plt.xlabel(\"Iteration\", fontsize=12)\n",
    "plt.ylabel(\"Time (seconds)\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 绘制 loss 曲线\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(range(1, len(loss_values) + 1), loss_values, label=\"Loss\", color=\"red\", marker='o')\n",
    "plt.title(\"Loss Curve\", fontsize=14)\n",
    "plt.xlabel(\"Iteration\", fontsize=12)\n",
    "plt.ylabel(\"Loss\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "c94acdf84d753673",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[taichi/rhi/cuda/cuda_driver.h:taichi::lang::CUDADriverFunction<void * *,unsigned __int64,void *>::operator ()@92] CUDA Error CUDA_ERROR_OUT_OF_MEMORY: out of memory while calling malloc_async_impl (cuMemAllocAsync)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 124\u001B[0m\n\u001B[0;32m    121\u001B[0m     execution_times[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxyzt\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start)\n\u001B[0;32m    123\u001B[0m     start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m--> 124\u001B[0m     xyzt_encoded \u001B[38;5;241m=\u001B[39m \u001B[43mxyzt_encoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxyzt_flat\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    125\u001B[0m     execution_times[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxyzt_encoder\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start)\n\u001B[0;32m    127\u001B[0m \u001B[38;5;66;03m#     start = time.time()\u001B[39;00m\n\u001B[0;32m    128\u001B[0m \u001B[38;5;66;03m#     raw_flat = mlp(xyzt_encoded)\u001B[39;00m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;66;03m#     execution_times[\"mlp\"].append(time.time() - start)\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    184\u001B[0m \u001B[38;5;66;03m# plt.grid(True)\u001B[39;00m\n\u001B[0;32m    185\u001B[0m \u001B[38;5;66;03m# plt.show()\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\VituralEnvs\\InstantPINF\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\VituralEnvs\\InstantPINF\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\Desktop\\241118\\Instant-PINF\\src\\encoder.py:369\u001B[0m, in \u001B[0;36mHashEncoderHyFluid.forward\u001B[1;34m(self, positions)\u001B[0m\n\u001B[0;32m    366\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, positions):\n\u001B[0;32m    367\u001B[0m     \u001B[38;5;66;03m# positions: (N, 4), normalized to [-1, 1]\u001B[39;00m\n\u001B[0;32m    368\u001B[0m     positions \u001B[38;5;241m=\u001B[39m positions \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0.5\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m0.5\u001B[39m\n\u001B[1;32m--> 369\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodule_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpositions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhash_table\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\VituralEnvs\\InstantPINF\\Lib\\site-packages\\torch\\autograd\\function.py:575\u001B[0m, in \u001B[0;36mFunction.apply\u001B[1;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[0;32m    572\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_are_functorch_transforms_active():\n\u001B[0;32m    573\u001B[0m     \u001B[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001B[39;00m\n\u001B[0;32m    574\u001B[0m     args \u001B[38;5;241m=\u001B[39m _functorch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39munwrap_dead_wrappers(args)\n\u001B[1;32m--> 575\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m    577\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_setup_ctx_defined:\n\u001B[0;32m    578\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    579\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIn order to use an autograd.Function with functorch transforms \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    580\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    581\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstaticmethod. For more details, please see \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    582\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    583\u001B[0m     )\n",
      "File \u001B[1;32m~\\Documents\\VituralEnvs\\InstantPINF\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:476\u001B[0m, in \u001B[0;36mcustom_fwd.<locals>.decorate_fwd\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    471\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m fwd(\n\u001B[0;32m    472\u001B[0m             \u001B[38;5;241m*\u001B[39m_cast(args, device_type, cast_inputs),\n\u001B[0;32m    473\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_cast(kwargs, device_type, cast_inputs),\n\u001B[0;32m    474\u001B[0m         )\n\u001B[0;32m    475\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 476\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfwd\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\241118\\Instant-PINF\\src\\encoder.py:277\u001B[0m, in \u001B[0;36mHashEncoderHyFluid.__init__.<locals>.ModuleFunction.forward\u001B[1;34m(ctx, input_pos, params)\u001B[0m\n\u001B[0;32m    273\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    274\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241m.\u001B[39mamp\u001B[38;5;241m.\u001B[39mcustom_fwd(cast_inputs\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32, device_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    275\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(ctx, input_pos, params):\n\u001B[0;32m    276\u001B[0m     output_embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_embedding[:input_pos\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39mcontiguous()\n\u001B[1;32m--> 277\u001B[0m     \u001B[43mtorch2ti\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput_fields\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_pos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontiguous\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    278\u001B[0m     torch2ti(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparameter_fields, params\u001B[38;5;241m.\u001B[39mcontiguous())\n\u001B[0;32m    280\u001B[0m     hash_encode_kernel(\n\u001B[0;32m    281\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_fields,\n\u001B[0;32m    282\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparameter_fields,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    289\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_scales,\n\u001B[0;32m    290\u001B[0m     )\n",
      "File \u001B[1;32m~\\Documents\\VituralEnvs\\InstantPINF\\Lib\\site-packages\\taichi\\lang\\kernel_impl.py:1113\u001B[0m, in \u001B[0;36m_kernel_impl.<locals>.wrapped\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1110\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(_func)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   1112\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1113\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mprimal\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1114\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m (TaichiCompilationError, TaichiRuntimeError) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1115\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m impl\u001B[38;5;241m.\u001B[39mget_runtime()\u001B[38;5;241m.\u001B[39mprint_full_traceback:\n",
      "File \u001B[1;32m~\\Documents\\VituralEnvs\\InstantPINF\\Lib\\site-packages\\taichi\\lang\\shell.py:27\u001B[0m, in \u001B[0;36m_shell_pop_print.<locals>.new_call\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(old_call)\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnew_call\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 27\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mold_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     28\u001B[0m     \u001B[38;5;66;03m# print's in kernel won't take effect until ti.sync(), discussion:\u001B[39;00m\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;66;03m# https://github.com/taichi-dev/taichi/pull/1303#discussion_r444897102\u001B[39;00m\n\u001B[0;32m     30\u001B[0m     \u001B[38;5;28mprint\u001B[39m(_ti_core\u001B[38;5;241m.\u001B[39mpop_python_print_buffer(), end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\VituralEnvs\\InstantPINF\\Lib\\site-packages\\taichi\\lang\\kernel_impl.py:1043\u001B[0m, in \u001B[0;36mKernel.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1041\u001B[0m     _logging\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;124mopt_level = 1 is enforced to enable gradient computation.\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m)\n\u001B[0;32m   1042\u001B[0m     impl\u001B[38;5;241m.\u001B[39mcurrent_cfg()\u001B[38;5;241m.\u001B[39mopt_level \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m-> 1043\u001B[0m key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mensure_compiled\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1044\u001B[0m kernel_cpp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompiled_kernels[key]\n\u001B[0;32m   1045\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlaunch_kernel(kernel_cpp, \u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[1;32m~\\Documents\\VituralEnvs\\InstantPINF\\Lib\\site-packages\\taichi\\lang\\kernel_impl.py:1011\u001B[0m, in \u001B[0;36mKernel.ensure_compiled\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m   1009\u001B[0m instance_id, arg_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmapper\u001B[38;5;241m.\u001B[39mlookup(args)\n\u001B[0;32m   1010\u001B[0m key \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc, instance_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mautodiff_mode)\n\u001B[1;32m-> 1011\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaterialize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43marg_features\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1012\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m key\n",
      "File \u001B[1;32m~\\Documents\\VituralEnvs\\InstantPINF\\Lib\\site-packages\\taichi\\lang\\kernel_impl.py:637\u001B[0m, in \u001B[0;36mKernel.materialize\u001B[1;34m(self, key, args, arg_features)\u001B[0m\n\u001B[0;32m    635\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    636\u001B[0m     key \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mautodiff_mode)\n\u001B[1;32m--> 637\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mruntime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaterialize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    639\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompiled_kernels:\n\u001B[0;32m    640\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\VituralEnvs\\InstantPINF\\Lib\\site-packages\\taichi\\lang\\impl.py:471\u001B[0m, in \u001B[0;36mPyTaichi.materialize\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    470\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmaterialize\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 471\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaterialize_root_fb\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaterialized\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    472\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmaterialized \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    474\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalidate_fields_builder()\n",
      "File \u001B[1;32m~\\Documents\\VituralEnvs\\InstantPINF\\Lib\\site-packages\\taichi\\lang\\impl.py:406\u001B[0m, in \u001B[0;36mPyTaichi.materialize_root_fb\u001B[1;34m(is_first_call)\u001B[0m\n\u001B[0;32m    403\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m root\u001B[38;5;241m.\u001B[39mfinalized:\n\u001B[0;32m    404\u001B[0m         root\u001B[38;5;241m.\u001B[39m_allocate_adjoint_checkbit()\n\u001B[1;32m--> 406\u001B[0m \u001B[43mroot\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfinalize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraise_warning\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mis_first_call\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    407\u001B[0m \u001B[38;5;28;01mglobal\u001B[39;00m _root_fb\n\u001B[0;32m    408\u001B[0m _root_fb \u001B[38;5;241m=\u001B[39m FieldsBuilder()\n",
      "File \u001B[1;32m~\\Documents\\VituralEnvs\\InstantPINF\\Lib\\site-packages\\taichi\\_snode\\fields_builder.py:170\u001B[0m, in \u001B[0;36mFieldsBuilder.finalize\u001B[1;34m(self, raise_warning)\u001B[0m\n\u001B[0;32m    165\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfinalize\u001B[39m(\u001B[38;5;28mself\u001B[39m, raise_warning\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m    166\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Constructs the SNodeTree and finalizes this builder.\u001B[39;00m\n\u001B[0;32m    167\u001B[0m \n\u001B[0;32m    168\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    169\u001B[0m \u001B[38;5;124;03m        raise_warning (bool): Raise warning or not.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 170\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_finalize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraise_warning\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompile_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\VituralEnvs\\InstantPINF\\Lib\\site-packages\\taichi\\_snode\\fields_builder.py:182\u001B[0m, in \u001B[0;36mFieldsBuilder._finalize\u001B[1;34m(self, raise_warning, compile_only)\u001B[0m\n\u001B[0;32m    180\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfinalized \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    181\u001B[0m impl\u001B[38;5;241m.\u001B[39mget_runtime()\u001B[38;5;241m.\u001B[39mfinalize_fields_builder(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m--> 182\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m SNodeTree(\u001B[43m_ti_core\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfinalize_snode_tree\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_snode_registry\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimpl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_runtime\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompile_only\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: [taichi/rhi/cuda/cuda_driver.h:taichi::lang::CUDADriverFunction<void * *,unsigned __int64,void *>::operator ()@92] CUDA Error CUDA_ERROR_OUT_OF_MEMORY: out of memory while calling malloc_async_impl (cuMemAllocAsync)"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
