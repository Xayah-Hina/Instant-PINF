{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-18T05:36:39.953747Z",
     "start_time": "2024-11-18T05:34:57.973333Z"
    }
   },
   "source": [
    "import train\n",
    "import torch\n",
    "import pathlib\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "manager = train.load_data(torch.device(\"cuda\"), data_path=pathlib.Path(\"C:/Users/imeho/Documents/DataSets/InstantPINF/ScalarReal\"))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Caching all \u001B[1;36m480\u001B[0m images.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Caching all <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">480</span> images.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3806cd9be583499d80b094b66c859646"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Caching all \u001B[1;36m120\u001B[0m images.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Caching all <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">120</span> images.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5aaeda5b5ecd450aaf8fc164ea12b793"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T05:36:40.277811Z",
     "start_time": "2024-11-18T05:36:40.247389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nerfstudio.model_components.ray_samplers import UniformSampler\n",
    "from nerfstudio.model_components.scene_colliders import NearFarCollider\n",
    "\n",
    "collider = NearFarCollider(near_plane=1.1, far_plane=1.5)\n",
    "sampler_uniform = UniformSampler(num_samples=192)"
   ],
   "id": "82ab71bdd429a6b1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T05:36:42.748044Z",
     "start_time": "2024-11-18T05:36:40.277811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import src.encoder as encoder\n",
    "import taichi as ti\n",
    "import numpy as np\n",
    "\n",
    "ti.init(arch=ti.cuda)\n",
    "xyzt_encoder = encoder.HashEncoderHyFluid(\n",
    "    min_res=np.array([16, 16, 16, 16]),\n",
    "    max_res=np.array([256, 256, 256, 128]),\n",
    "    num_scales=16,\n",
    "    max_params=2 ** 19,\n",
    ")\n",
    "xyzt_encoder.to(device)"
   ],
   "id": "eb31ba2586f14854",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Taichi] version 1.7.2, llvm 15.0.1, commit 0131dce9, win, python 3.11.0\n",
      "[Taichi] Starting on arch=cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HashEncoderHyFluid()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T05:37:26.918353Z",
     "start_time": "2024-11-18T05:37:26.288916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nerfstudio.field_components.mlp import MLP\n",
    "import src.radam as radam\n",
    "\n",
    "mlp_base = MLP(\n",
    "    in_dim=xyzt_encoder.num_scales * xyzt_encoder.features_per_level,\n",
    "    num_layers=2,\n",
    "    layer_width=64,\n",
    "    out_dim=1,\n",
    "    out_activation=torch.nn.ReLU(),\n",
    ")\n",
    "mlp_base.to(device)\n",
    "learned_rgb = torch.nn.Parameter(torch.tensor([0.0], device=device))\n",
    "\n",
    "grad_vars = list(mlp_base.parameters()) + [learned_rgb]\n",
    "embedding_params = list(xyzt_encoder.parameters())\n",
    "\n",
    "optimizer = radam.RAdam([\n",
    "    {'params': grad_vars, 'weight_decay': 1e-6},\n",
    "    {'params': embedding_params, 'eps': 1e-15}\n",
    "], lr=0.01, betas=(0.9, 0.99))"
   ],
   "id": "56f3a89c1c79cd8b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T05:37:28.142185Z",
     "start_time": "2024-11-18T05:37:28.139442Z"
    }
   },
   "cell_type": "code",
   "source": "raw2alpha = lambda raw, dists, act_fn=torch.nn.functional.relu: 1. - torch.exp(-act_fn(raw) * dists)",
   "id": "2ad0fc75c2f9cf03",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-18T05:37:28.675507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nerfstudio.model_components.losses import MSELoss\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import src.datamanager as datamanager\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "for i in tqdm.tqdm(range(100)):\n",
    "    ray_bundle, batch = manager.next_train()\n",
    "    collider(ray_bundle)\n",
    "    ray_samples_uniform = sampler_uniform(ray_bundle)\n",
    "    positions = ray_samples_uniform.frustums.get_positions()\n",
    "    frames = datamanager.image_idx_to_frame(\n",
    "        image_indices=batch['indices'][:, 0],\n",
    "        all_frames=manager.train_dataset.metadata['all_frames'])\n",
    "    frames_expanded = frames.to(device).view(positions.shape[0], 1, 1).expand(-1, positions.shape[1], -1)\n",
    "    xyzt = torch.cat((positions, frames_expanded), dim=-1)\n",
    "    xyzt_flat = xyzt.reshape(-1, 4)\n",
    "    xyzt_encoded = xyzt_encoder(xyzt_flat)\n",
    "\n",
    "    raw_flat = mlp_base(xyzt_encoded)\n",
    "    raw = raw_flat.reshape(xyzt.shape[0], xyzt.shape[1], raw_flat.shape[-1])\n",
    "\n",
    "    dists = ray_samples_uniform.deltas\n",
    "    rgb = torch.ones(3, device=device) * (0.6 + torch.tanh(learned_rgb) * 0.4)\n",
    "    alpha = raw2alpha(raw[..., -1], dists[..., -1])\n",
    "    weights = alpha * torch.cumprod(torch.cat([torch.ones((alpha.shape[0], 1), device=device), 1. - alpha + 1e-10], -1),\n",
    "                                    -1)[:, :-1]\n",
    "    rgb_map = torch.sum(weights[..., None] * rgb, -2)\n",
    "\n",
    "    rgb_loss = MSELoss()\n",
    "    image = batch['image'].to(device)\n",
    "    loss = rgb_loss(rgb_map, image)\n",
    "    loss_history.append(loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    new_lrate = 5e-4 * (0.1 ** (i / 250))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = new_lrate\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss_history, label=\"Loss\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss over Training Iterations\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "e30782bc3077299c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [00:27<00:23,  2.14it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c932e21fbbfaeef3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
