{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "b10f76885f213567"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Manager",
   "id": "7823e751156b7870"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T03:06:08.155837Z",
     "start_time": "2024-11-17T03:05:29.094221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datamanager\n",
    "import torch\n",
    "import pathlib\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "config = datamanager.HyFluidNeRFDataManagerConfig(dataparser=datamanager.HyFluidDataParserConfig())\n",
    "config.dataparser.data = pathlib.Path(\"../data/ScalarReal\")\n",
    "manager: datamanager.HyFluidNeRFDataManager = config.setup(device=torch.device(\"cuda\"))\n",
    "manager.to(device)"
   ],
   "id": "e5fe41d7b99d2258",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Caching all \u001B[1;36m480\u001B[0m images.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Caching all <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">480</span> images.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "feb47f23e1f543488813a19b5cf138e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Caching all \u001B[1;36m120\u001B[0m images.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Caching all <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">120</span> images.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df1c631b072c4796a976551a8f9ed5a1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HyFluidNeRFDataManager(\n",
       "  (train_ray_generator): RayGenerator()\n",
       "  (eval_ray_generator): RayGenerator()\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T03:06:08.200763Z",
     "start_time": "2024-11-17T03:06:08.176103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nerfstudio.model_components.ray_samplers import UniformSampler\n",
    "from nerfstudio.model_components.scene_colliders import NearFarCollider\n",
    "\n",
    "collider = NearFarCollider(near_plane=1.1, far_plane=1.5)\n",
    "sampler_uniform = UniformSampler(num_samples=192)"
   ],
   "id": "62a35043cd5bdf8a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T03:06:10.304283Z",
     "start_time": "2024-11-17T03:06:08.275601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import encoder\n",
    "import taichi as ti\n",
    "import numpy as np\n",
    "\n",
    "ti.init(arch=ti.cuda)\n",
    "xyzt_encoder = encoder.HashEncoderHyFluid(\n",
    "    min_res=np.array([16, 16, 16, 16]),\n",
    "    max_res=np.array([256, 256, 256, 128]),\n",
    "    num_scales=16,\n",
    "    max_params=2 ** 19,\n",
    ")\n",
    "xyzt_encoder.to(device)"
   ],
   "id": "17580dbbb8516070",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Taichi] version 1.7.2, llvm 15.0.1, commit 0131dce9, win, python 3.11.0\n",
      "[Taichi] Starting on arch=cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HashEncoderHyFluid()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T03:06:10.636905Z",
     "start_time": "2024-11-17T03:06:10.314036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nerfstudio.field_components.mlp import MLP\n",
    "import radam\n",
    "\n",
    "mlp_base = MLP(\n",
    "    in_dim=xyzt_encoder.num_scales * xyzt_encoder.features_per_level,\n",
    "    num_layers=2,\n",
    "    layer_width=64,\n",
    "    out_dim=1,\n",
    "    out_activation=torch.nn.ReLU(),\n",
    ")\n",
    "mlp_base.to(device)\n",
    "learned_rgb = torch.nn.Parameter(torch.tensor([0.0], device=device))\n",
    "\n",
    "grad_vars = list(mlp_base.parameters()) + [learned_rgb]\n",
    "embedding_params = list(xyzt_encoder.parameters())\n",
    "\n",
    "optimizer = radam.RAdam([\n",
    "    {'params': grad_vars, 'weight_decay': 1e-6},\n",
    "    {'params': embedding_params, 'eps': 1e-15}\n",
    "], lr=0.01, betas=(0.9, 0.99))"
   ],
   "id": "aa82b74181c03f29",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T03:06:10.803187Z",
     "start_time": "2024-11-17T03:06:10.800143Z"
    }
   },
   "cell_type": "code",
   "source": "raw2alpha = lambda raw, dists, act_fn=torch.nn.functional.relu: 1. - torch.exp(-act_fn(raw) * dists)",
   "id": "624461e02c9d5d9e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-17T03:06:10.820132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nerfstudio.model_components.losses import MSELoss\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "for i in tqdm.tqdm(range(10000)):\n",
    "    ray_bundle, batch = manager.next_train()\n",
    "    collider(ray_bundle)\n",
    "    ray_samples_uniform = sampler_uniform(ray_bundle)\n",
    "    positions = ray_samples_uniform.frustums.get_positions()\n",
    "    frames = datamanager.image_idx_to_frame(\n",
    "        image_indices=batch['indices'][:, 0],\n",
    "        all_frames=manager.train_dataset.metadata['all_frames'])\n",
    "    frames_expanded = frames.to(device).view(positions.shape[0], 1, 1).expand(-1, positions.shape[1], -1)\n",
    "    xyzt = torch.cat((positions, frames_expanded), dim=-1)\n",
    "    xyzt_flat = xyzt.reshape(-1, 4)\n",
    "    xyzt_encoded = xyzt_encoder(xyzt_flat)\n",
    "\n",
    "    raw_flat = mlp_base(xyzt_encoded)\n",
    "    raw = raw_flat.reshape(xyzt.shape[0], xyzt.shape[1], raw_flat.shape[-1])\n",
    "\n",
    "    dists = ray_samples_uniform.deltas\n",
    "    rgb = torch.ones(3, device=device) * (0.6 + torch.tanh(learned_rgb) * 0.4)\n",
    "    alpha = raw2alpha(raw[..., -1], dists[..., -1])\n",
    "    weights = alpha * torch.cumprod(torch.cat([torch.ones((alpha.shape[0], 1), device=device), 1. - alpha + 1e-10], -1),\n",
    "                                    -1)[:, :-1]\n",
    "    rgb_map = torch.sum(weights[..., None] * rgb, -2)\n",
    "\n",
    "    rgb_loss = MSELoss()\n",
    "    image = batch['image'].to(device)\n",
    "    loss = rgb_loss(rgb_map, image)\n",
    "    loss_history.append(loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    new_lrate = 5e-4 * (0.1 ** (i / 250))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = new_lrate\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss_history, label=\"Loss\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss over Training Iterations\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "939174d77221adf1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 17/10000 [00:11<1:20:48,  2.06it/s]"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
