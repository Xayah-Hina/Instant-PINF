{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-17T02:16:01.627142Z",
     "start_time": "2024-11-17T02:15:28.570729Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "import datamanager\n",
    "import torch\n",
    "import pathlib\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "config = datamanager.HyFluidNeRFDataManagerConfig(dataparser=datamanager.HyFluidDataParserConfig())\n",
    "config.dataparser.data = pathlib.Path(\"../data/ScalarReal\")\n",
    "manager: datamanager.HyFluidNeRFDataManager = config.setup(device=torch.device(\"cuda\"))\n",
    "manager.to(device)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Caching all \u001B[1;36m480\u001B[0m images.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Caching all <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">480</span> images.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6884e3a2f74644f2bc4b19936cbd0fdb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Caching all \u001B[1;36m120\u001B[0m images.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Caching all <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">120</span> images.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9dc9325fcf0f4590b87c5727af9f99a1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HyFluidNeRFDataManager(\n",
       "  (train_ray_generator): RayGenerator()\n",
       "  (eval_ray_generator): RayGenerator()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:16:02.219394Z",
     "start_time": "2024-11-17T02:16:01.637148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ray_bundle, batch = manager.next_train()\n",
    "print(ray_bundle.shape)\n",
    "print(batch['image'].shape)\n",
    "print(batch['indices'].shape)"
   ],
   "id": "f09ad6a40e8d2654",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024])\n",
      "torch.Size([1024, 3])\n",
      "torch.Size([1024, 3])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:16:02.327208Z",
     "start_time": "2024-11-17T02:16:02.294793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nerfstudio.model_components.ray_samplers import UniformSampler\n",
    "from nerfstudio.model_components.scene_colliders import NearFarCollider\n",
    "from nerfstudio.cameras.rays import RaySamples\n",
    "\n",
    "collider = NearFarCollider(near_plane=1.1, far_plane=1.5)\n",
    "sampler_uniform = UniformSampler(num_samples=192)\n",
    "\n",
    "collider(ray_bundle)\n",
    "ray_samples_uniform: RaySamples = sampler_uniform(ray_bundle)\n",
    "\n",
    "print(ray_samples_uniform.shape)"
   ],
   "id": "b5a3e5d18242fd0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 192])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:16:02.373996Z",
     "start_time": "2024-11-17T02:16:02.370366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_positions = ray_samples_uniform.frustums.get_start_positions()\n",
    "positions = ray_samples_uniform.frustums.get_positions()\n",
    "\n",
    "print(start_positions.shape)\n",
    "print(positions.shape)"
   ],
   "id": "9ece48fc74588730",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 192, 3])\n",
      "torch.Size([1024, 192, 3])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:16:02.650687Z",
     "start_time": "2024-11-17T02:16:02.424692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.savez_compressed(\n",
    "    \"positions.npz\",\n",
    "    start_positions=start_positions.cpu().numpy(),\n",
    "    positions=positions.cpu().numpy()\n",
    ")"
   ],
   "id": "9f5323936f924fff",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:16:02.726836Z",
     "start_time": "2024-11-17T02:16:02.703807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_indices = batch['indices'][:, 0]\n",
    "all_frames = manager.train_dataset.metadata['all_frames']\n",
    "frames = datamanager.image_idx_to_frame(image_indices, all_frames)\n",
    "frames_expanded = frames.to(positions.device).view(positions.shape[0], 1, 1).expand(-1, positions.shape[1], -1)\n",
    "xyzt = torch.cat((positions, frames_expanded), dim=-1)\n",
    "\n",
    "print(all_frames)\n",
    "print(image_indices)\n",
    "print(frames)\n",
    "print(frames.shape)\n",
    "print(xyzt.shape)"
   ],
   "id": "ff2d07a37e190d89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[120, 120, 120, 120]\n",
      "tensor([ 36.5588, 424.4061, 462.1608,  ..., 276.2364, 333.5029, 195.6115])\n",
      "tensor([ 36.5588,  64.4061, 102.1608,  ...,  36.2364,  93.5029,  75.6115])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 192, 4])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:21:18.590805Z",
     "start_time": "2024-11-17T02:21:15.993034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import encoder\n",
    "import taichi as ti\n",
    "\n",
    "ti.init(arch=ti.cuda)\n",
    "xyzt_encoder = encoder.HashEncoderHyFluid(\n",
    "    min_res=np.array([16, 16, 16, 16]),\n",
    "    max_res=np.array([256, 256, 256, 128]),\n",
    "    num_scales=16,\n",
    "    max_params=2 ** 19,\n",
    ")\n",
    "xyzt_encoder.to(device)\n",
    "\n",
    "xyzt_flat = xyzt.reshape(-1, 4)\n",
    "xyzt_encoded = xyzt_encoder(xyzt_flat)"
   ],
   "id": "524f7973c06cee52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Taichi] Starting on arch=cuda\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:21:27.287301Z",
     "start_time": "2024-11-17T02:21:27.284060Z"
    }
   },
   "cell_type": "code",
   "source": "print(xyzt_encoded.shape)",
   "id": "9a63d93ec95879e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([196608, 32])\n",
      "cuda:0\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:27:32.909105Z",
     "start_time": "2024-11-17T02:27:32.902824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nerfstudio.field_components.mlp import MLP\n",
    "import radam\n",
    "\n",
    "mlp_base = MLP(\n",
    "    in_dim=xyzt_encoder.num_scales * xyzt_encoder.features_per_level,\n",
    "    num_layers=2,\n",
    "    layer_width=64,\n",
    "    out_dim=1,\n",
    "    out_activation=torch.nn.ReLU(),\n",
    ")\n",
    "mlp_base.to(device)\n",
    "learned_rgb = torch.nn.Parameter(torch.tensor([0.0], device=device))\n",
    "\n",
    "grad_vars = list(mlp_base.parameters()) + [learned_rgb]\n",
    "embedding_params = list(xyzt_encoder.parameters())\n",
    "\n",
    "optimizer = radam.RAdam([\n",
    "    {'params': grad_vars, 'weight_decay': 1e-6},\n",
    "    {'params': embedding_params, 'eps': 1e-15}\n",
    "], lr=0.01, betas=(0.9, 0.99))"
   ],
   "id": "c47b59ed8a2f74da",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:27:36.399618Z",
     "start_time": "2024-11-17T02:27:36.395256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "density_flat = mlp_base(xyzt_encoded)\n",
    "density = density_flat.reshape(xyzt.shape[0], xyzt.shape[1], density_flat.shape[-1])\n",
    "print(f'density: {density.shape}')"
   ],
   "id": "47396eb0ee28b302",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "density: torch.Size([1024, 192, 1])\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:27:38.637423Z",
     "start_time": "2024-11-17T02:27:38.621921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw2alpha = lambda raw, dists, act_fn=torch.nn.functional.relu: 1. - torch.exp(-act_fn(raw) * dists)\n",
    "dists = ray_samples_uniform.deltas\n",
    "rgb = torch.ones(3, device=device) * (0.6 + torch.tanh(learned_rgb) * 0.4)\n",
    "alpha = raw2alpha(density[..., -1], dists[..., -1])\n",
    "weights = alpha * torch.cumprod(torch.cat([torch.ones((alpha.shape[0], 1), device=device), 1. - alpha + 1e-10], -1), -1)[:, :-1]\n",
    "rgb_map = torch.sum(weights[..., None] * rgb, -2)\n",
    "\n",
    "print(f'dists: {dists.shape}')\n",
    "print(f'alpha: {alpha.shape}')\n",
    "print(f'weights: {weights.shape}')\n",
    "print(f'rgb_map: {rgb_map.shape}')"
   ],
   "id": "367ade216b5bdb57",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dists: torch.Size([1024, 192, 1])\n",
      "alpha: torch.Size([1024, 192])\n",
      "weights: torch.Size([1024, 192])\n",
      "rgb_map: torch.Size([1024, 3])\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T02:41:42.322586Z",
     "start_time": "2024-11-17T02:41:41.378798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nerfstudio.model_components.losses import MSELoss\n",
    "rgb_loss = MSELoss()\n",
    "\n",
    "image = batch['image'].to(device)\n",
    "loss = rgb_loss(rgb_map, image)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(loss.shape)"
   ],
   "id": "404eaf1e5897156b",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[56], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m loss \u001B[38;5;241m=\u001B[39m rgb_loss(rgb_map, image)\n\u001B[0;32m      7\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m----> 8\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(loss\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[1;32m~\\Desktop\\HinaPE-AI\\PINF\\venv\\Lib\\site-packages\\torch\\_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    491\u001B[0m     )\n\u001B[1;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\HinaPE-AI\\PINF\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "execution_count": 56
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
